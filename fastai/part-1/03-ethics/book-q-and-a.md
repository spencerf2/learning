# Chapter 3: Data Ethics - Questionnaire

<https://github.com/fastai/fastbook/blob/master/03_ethics.ipynb>

Questions from the fastai book, Chapter 3.

## Questions

1. Does ethics provide a list of "right answers"?

2. How can working with people of different backgrounds help when considering
   ethical questions?

3. What was the role of IBM in Nazi Germany? Why did the company participate
   as it did? Why did the workers participate?

4. What was the role of the first person jailed in the Volkswagen diesel
   scandal?

5. What was the problem with a database of suspected gang members maintained
   by California law enforcement officials?

6. Why did YouTube's recommendation algorithm recommend videos of partially
   clothed children to pedophiles, even though no employee at Google had
   programmed this feature?

7. What are the problems with the centrality of metrics?

8. Why did Meetup.com not include gender in its recommendation system for
   tech meetups?

9. What are the six types of bias in machine learning, according to Suresh
   and Guttag?

10. Give two examples of historical race bias in the US.

11. Where are most images in ImageNet from?

12. In the paper "Does Machine Learning Automate Moral Hazard and Error" why
    is sinusitis found to be predictive of a stroke?

13. What is representation bias?

14. How are machines and people different, in terms of their use for making
    decisions?

15. Is disinformation the same as "fake news"?

16. Why is disinformation through auto-generated text a particularly
    significant issue?

17. What are the five ethical lenses described by the Markkula Center?

18. Where is policy an appropriate tool for addressing data ethics issues?
